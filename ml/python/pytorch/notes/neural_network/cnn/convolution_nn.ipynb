{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络\n",
    "\n",
    "卷积神经网络中的输入和输出有些区别, 需要重新设计, 训练模块基本上是一致的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先读取数据\n",
    "\n",
    "- 分别创建训练集和测试集\n",
    "- datasetloader 来进行迭代数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集下载完毕\n",
      "测试集下载完毕\n"
     ]
    }
   ],
   "source": [
    "# 定义超参数\n",
    "input_size = 28  # 图像的像素为28*28*1 注意, 这里是3维的数据\n",
    "num_classes = 10  # 标签的种类, 也就是最终分类的数量\n",
    "num_epoches = 3  # 训练循环周期, 总共训练3次\n",
    "batch_size = 64  # 一个批次为64张图片\n",
    "\n",
    "# 下载训练集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='../../data/mnist2/',  # 数据下载的位置\n",
    "    train=True,  # 默认就是true, 也就是下载训练集训练集的文件是train-images-idx3-ubyte\n",
    "    # 使用transform包下面的ToTensor转换所有的数据为tensor的形式, 也就是封装数据, 注意这里需要方法的返回值, 而不是传入方法\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True  # 下载到本地, 可以直接使用网络流进行训练\n",
    ")\n",
    "print(\"训练集下载完毕\")\n",
    "\n",
    "# 下载测试集\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='../../data/mnist2/',\n",
    "    train=False,  # 下载测试集, 测试集的文件名为 t10k-images-idx3-ubyte,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()  # 转换为Tensor格式\n",
    ")\n",
    "print(\"测试集下载完毕\")\n",
    "\n",
    "# 将训练集和测试集封装进入loader中\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,  # 必须是map类型或者iterable类型, MNIST实现了map所需要的方法\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络模块构建\n",
    "\n",
    "- 一般卷积层, relu 层, 池化层可以写成一个套餐, 直接加入进来进行操作. 这样可以看做是模块化的, 因为 relu 和池化层都不能算是一个计算的层, 而是一个加单的加减.\n",
    "- 注意卷积最后结果还是一个特征图, 需要把图转换成向量才能做分类或者回归任务.\n",
    "\n",
    "这里, 计算卷积特征图的公式为：\n",
    "\n",
    "长度: $h_2=\\frac{H_1-F_H-2P}{S} + 1$\n",
    "宽度: $W_2=\\frac{W_1-F_W-2P}{S} + 1$\n",
    "\n",
    "这里$h_1,w_1$表示的是特征图的长宽, P 表示的是 padding 的大小, S 表示的是卷积核的步长\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "import torch.nn as nn\n",
    "\n",
    "\"\"\"\n",
    "这里引入nn模块, 在建立class的时候继承的是nn.Module的模块\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    # 定义一个网络模型, 网络模型的名字为CNN, 也就是这个类\n",
    "    def __init__(self) -> None:\n",
    "        # 调用父类的方法, 将所有的方法继承过来\n",
    "        # 这里调用一下父类的初始化方法, 初始化方法帮我们初始化所有的参数. 也可以使用下面的来赋予self到初始化方法中\n",
    "        super().__init__()\n",
    "        # super(CNN, self).__init__()\n",
    "\n",
    "        # 第一个卷积模块, 如上面所说, 这个模块包含了relu和池化层\n",
    "        # Sequential模块包含了多个参数, 每一个参数都是一个操作, 比如：\n",
    "        #   >>> model = nn.Sequential(nn.Conv2d(1, 20, 5),nn.ReLU(),nn.Conv2d(20, 64, 5),nn.ReLU())\n",
    "        # 上面就创造了一个2个卷积层和2个relu层的网络结构\n",
    "        #\n",
    "        # 第一个二维卷积层, 根据公式得到的大小：\n",
    "        #   ((28 - 5 + 2 * 2） / 1） + 1 = 28\n",
    "        # 因此第一个卷积层的二维卷积核得到的每一个特征图的大小为28*28大小是不变的\n",
    "        # 经过relu层是不变的\n",
    "        # 但是经过池化层 由于我们使用的是长度为2的核, 因此应该会得到一个 14*14的特征图\n",
    "        # 我们总共需要输出16个图片, 因此会有16个卷积核, 因此第一个模块我们的输出就是14*14*16\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(  # 创建一个二维的卷积层\n",
    "                in_channels=1,  # 输入一个特征图\n",
    "                out_channels=16,  # 输出16个特征图, 也就是有16个卷积核\n",
    "                kernel_size=5,  # 每一个卷积核的大小为5, 也就是5x5的卷积核\n",
    "                stride=1,  # 卷积核每次移动的的步长为1\n",
    "                padding=2  # 图片外侧padding2个格\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)  # 生成一个max池化层, 核长度为2x2\n",
    "        )\n",
    "\n",
    "        # 第二个卷积模块, 输入16个特征图, 输出32个特征图.\n",
    "        # 我们输入的特征图为 14*14*16 (我们上面得到的)\n",
    "        # 第二层我们一样使用长度为5的核, 因此\n",
    "        #   (14 - 5 + 4)/1 + 1 = 16\n",
    "        # 我们得到的结果保持不变, 特征图为14*14的图片\n",
    "        # 经过relu层, 特征不变\n",
    "        # 经过池化层, 因为我们使用了长度为2的核, 因此 14/2 = 7, 我们所有的特征图都变成了7*7的特征图\n",
    "        # 而我们总共需要输出32个图片, 因此7*7*32\n",
    "        self.conv2 = nn.Sequential(\n",
    "            # 16个特征图输入, 32个特征图输出, 5x5的卷积核, 1个步长, 外部padding2个格\n",
    "            # 也可以使用较为复杂的卷积核设置：\n",
    "            #   >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # 创建2层的全链接层, 第一层的数量为32 * 7 * 7, 第二层的数量为10, 也就是输出层\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    # 前向传播, 这里的输入x就是一张图片的数据, 也就是一个Tensor矩阵\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # 这里对PyTorch的Tensor做了一个reshape的操作, view方法就是维度变换, 这里将所有的大小直接拉伸为1维的向量\n",
    "        #\n",
    "        # 比如：x = torch.tensor([1,2,3,4])\n",
    "        # 我们想把x拉伸成一个2x2的矩阵我们可以用 x.view(2,2) 但是第二个参数我们没有必要算的,\n",
    "        # 因为如果第一个参数固定了, 第二个参数必然是一个定值, 我们可以让pytorch进行计算, 可以使用-1\n",
    "        # 因此可以使用 x.view(2,-1) 或者 x.view(-1,2) 效果是一样的\n",
    "        #\n",
    "        # 同样size方法也是将tensor自带的属性打印出来, 这里的参数是维度的意思\n",
    "        # t = torch.empty(3, 4, 5)\n",
    "        # t.size() # 结果是tensor.size(3). 此时我们给size加上一个获取第0个参数, 我们就可以得到3\n",
    "        # t.size(0) # 结果就是3, 因为我们获取的是tensor中第0个数据, 也就是3.\n",
    "        # 如果维度更高的话我们获取的就是不同维度的size, 但是这里的size返回结果是一个单维度的数据, 用法就很简单.\n",
    "        #\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准确率的评估函数\n",
    "\n",
    "使用准确率来计算预测值和结果值复合的值是多少\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个方法来计算当前模型的准确率\n",
    "# 在这里调用了一个max方法, 这个max方法可以将Tensor矩阵的最大值求出来\n",
    "# 如果直接使用 torch.max(torch.Tensor) 方法返回一个tensor, 里面包含着最大值 troch.tensor(12345)\n",
    "#   这个值是整个矩阵的最大值, 无论行列\n",
    "# 如果加上一个参数的话就是获取行或者列的最大值, 0 就是列, 1 就是行\n",
    "# 下面的就是获得所有列的最大值, 返回一个tensor, 返回的tensor是一个array\n",
    "#   torch.max(predictions.data, 0)\n",
    "#   返回的是 torch.return_types.max([[1,2,3,2],[0,1,1,1]]) 第一个参数是数值, 第二个参数是index\n",
    "# 如果需要获得所有行的值就用参数1, torch.max(data, 1), 然后获取index的位置就是torch.max(data, 1)[1]\n",
    "def accuracy(predictions, labels):\n",
    "    # 获得每一行最大值的index\n",
    "    pred_index = torch.max(predictions.data, 1)[1]\n",
    "    rights = pred_index.eq(labels.data.view_as(pred_index)).sum()\n",
    "    return rights, len(labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练！\n",
    "\n",
    "我们使用常用的交叉熵损失函数 CrossEntropyLoss(), 什么是交叉熵？\n",
    "\n",
    "交叉熵主要是用来判定实际的输出与期望的输出的接近程度,为什么这么说呢,举个例子：在做分类的训练的时候,如果一个样本属于第 K 类,那么这个类别所对应的的输出节点的输出值应该为 1,而其他节点的输出都为 0,即[0,0,1,0,….0,0],这个数组也就是样本的 Label,是神经网络最期望的输出结果。也就是说用它来衡量网络的输出与标签的差异,利用这种差异经过反向传播去更新网络参数。\n",
    "\n",
    "举个例子：假如小明和小王去打靶,那么打靶结果其实是一个 0-1 分布,X 的取值有{0：打中,1：打不中}。在打靶之前我们知道小明和小王打中的先验概率为 10%,99.9%。根据上面的信息量的介绍,我们可以分别得到小明和小王打靶打中的信息量。但是如果我们想进一步度量小明打靶结果的不确定度,这就需要用到熵的概念了。那么如何度量呢,那就要采用期望了。我们对所有可能事件所带来的信息量求期望,其结果就能衡量小明打靶的不确定度.\n",
    "\n",
    "因此也是计算二分类问题的很好损失函数.\n",
    "\n",
    "对优化器的详解：\n",
    "<https://blog.csdn.net/qq_39852676/article/details/105919329>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前epoch: 0 [0/60000 (0%)] 损失: 2.296350 | 训练集准确率：6.25% 测试集正确率: 18.33%\n",
      "当前epoch: 0 [6400/60000 (11%)] 损失: 0.369493 | 训练集准确率：74.15% 测试集正确率: 91.34%\n",
      "当前epoch: 0 [12800/60000 (21%)] 损失: 0.140937 | 训练集准确率：83.64% 测试集正确率: 95.38%\n",
      "当前epoch: 0 [19200/60000 (32%)] 损失: 0.147676 | 训练集准确率：87.66% 测试集正确率: 96.62%\n",
      "当前epoch: 0 [25600/60000 (43%)] 损失: 0.066431 | 训练集准确率：89.71% 测试集正确率: 96.98%\n",
      "当前epoch: 0 [32000/60000 (53%)] 损失: 0.058125 | 训练集准确率：91.11% 测试集正确率: 97.29%\n",
      "当前epoch: 0 [38400/60000 (64%)] 损失: 0.110508 | 训练集准确率：92.10% 测试集正确率: 97.80%\n",
      "当前epoch: 0 [44800/60000 (75%)] 损失: 0.122578 | 训练集准确率：92.84% 测试集正确率: 97.88%\n",
      "当前epoch: 0 [51200/60000 (85%)] 损失: 0.052326 | 训练集准确率：93.42% 测试集正确率: 97.70%\n",
      "当前epoch: 0 [57600/60000 (96%)] 损失: 0.088413 | 训练集准确率：93.85% 测试集正确率: 97.94%\n",
      "当前epoch: 1 [0/60000 (0%)] 损失: 0.060140 | 训练集准确率：98.44% 测试集正确率: 98.19%\n",
      "当前epoch: 1 [6400/60000 (11%)] 损失: 0.050169 | 训练集准确率：97.85% 测试集正确率: 98.13%\n",
      "当前epoch: 1 [12800/60000 (21%)] 损失: 0.075982 | 训练集准确率：97.94% 测试集正确率: 98.43%\n",
      "当前epoch: 1 [19200/60000 (32%)] 损失: 0.044543 | 训练集准确率：98.06% 测试集正确率: 98.33%\n",
      "当前epoch: 1 [25600/60000 (43%)] 损失: 0.050262 | 训练集准确率：98.10% 测试集正确率: 98.43%\n",
      "当前epoch: 1 [32000/60000 (53%)] 损失: 0.053473 | 训练集准确率：98.13% 测试集正确率: 98.75%\n",
      "当前epoch: 1 [38400/60000 (64%)] 损失: 0.032780 | 训练集准确率：98.17% 测试集正确率: 98.37%\n",
      "当前epoch: 1 [44800/60000 (75%)] 损失: 0.010274 | 训练集准确率：98.22% 测试集正确率: 98.66%\n",
      "当前epoch: 1 [51200/60000 (85%)] 损失: 0.034818 | 训练集准确率：98.25% 测试集正确率: 98.65%\n",
      "当前epoch: 1 [57600/60000 (96%)] 损失: 0.016400 | 训练集准确率：98.29% 测试集正确率: 98.67%\n",
      "当前epoch: 2 [0/60000 (0%)] 损失: 0.069330 | 训练集准确率：95.31% 测试集正确率: 98.81%\n",
      "当前epoch: 2 [6400/60000 (11%)] 损失: 0.010231 | 训练集准确率：98.64% 测试集正确率: 98.54%\n",
      "当前epoch: 2 [12800/60000 (21%)] 损失: 0.045044 | 训练集准确率：98.80% 测试集正确率: 98.72%\n",
      "当前epoch: 2 [19200/60000 (32%)] 损失: 0.022151 | 训练集准确率：98.81% 测试集正确率: 98.72%\n",
      "当前epoch: 2 [25600/60000 (43%)] 损失: 0.013217 | 训练集准确率：98.78% 测试集正确率: 98.99%\n",
      "当前epoch: 2 [32000/60000 (53%)] 损失: 0.084262 | 训练集准确率：98.75% 测试集正确率: 98.69%\n",
      "当前epoch: 2 [38400/60000 (64%)] 损失: 0.011359 | 训练集准确率：98.69% 测试集正确率: 98.90%\n",
      "当前epoch: 2 [44800/60000 (75%)] 损失: 0.004138 | 训练集准确率：98.71% 测试集正确率: 98.85%\n",
      "当前epoch: 2 [51200/60000 (85%)] 损失: 0.007212 | 训练集准确率：98.74% 测试集正确率: 98.94%\n",
      "当前epoch: 2 [57600/60000 (96%)] 损失: 0.171296 | 训练集准确率：98.75% 测试集正确率: 99.03%\n"
     ]
    }
   ],
   "source": [
    "# 将我们刚刚定义的网络模型拿过来, 创建一个实体类\n",
    "nnet = CNN()\n",
    "\n",
    "# 损失函数, 损失函数会实现一个forward(data,targetForCompare)的方法, 可以计算损失值\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "r\"\"\"\n",
    "优化器\n",
    "优化算法的功能,是通过改善训练方式,来最小化(或最大化)损失函数E(x)。自适应算法能很快收敛,并快速找到参数更新中正确的目标方向; 而标准的SGD、NAG和动量项等方法收敛缓慢,且很难找到正确的方向。\n",
    "\n",
    "torch.optim是一个实现了各种优化算法的库。大部分常用的方法得到支持,并且接口具备足够的通用性,使得未来能够集成更加复杂的方法\n",
    "为了使用torch.optim,你需要构建一个optimizer对象。这个对象能够保持当前参数状态并基于计算得到的梯度进行参数更新。为了构建一个Optimizer,你需要给它一个包含了需要优化的参数(必须都是Variable对象)的iterable。然后,你可以设置optimizer的参\n",
    "数选项,比如学习率,权重衰减,等等。\n",
    "Optimizer也支持为每个参数单独设置选项。若想这么做,不要直接传入Variable的iterable,而是传入dict的iterable。每一个dict都分别定\n",
    "义了一组参数,并且包含一个param键,这个键对应参数的列表。其他的键应该optimizer所接受的其他参数的关键字相匹配,并且会被用于对这组参数的\n",
    "\"\"\"\n",
    "optimizer = optim.Adam(nnet.parameters(), lr=0.001)  # 我们定义一个普通的随机梯度下降算法的优化器\n",
    "\n",
    "r\"\"\"\n",
    "开始训练：\n",
    "我们使用一个for循环来进行训练\n",
    "\"\"\"\n",
    "for epoch in range(num_epoches):\n",
    "    train_rights = []  # 当前的epoch的结果保存下来的容器\n",
    "\n",
    "    # 这里用的enumerate(sequence, [start=0])就是直接将sequence序列的迭代出来.\n",
    "    #   for i, element in enumerate(seq): # 这里就可以得到index和当前迭代的数值\n",
    "    # 在迭代出来的结果中, 我们直接在方法中将data和target结构出来\n",
    "    # 验证网络处于 train 或 eval 模式,其最后结果是不一样的\n",
    "    # train模式启用 BatchNormalization 和 Dropout, 而eval则不启用\n",
    "    for index, (data, target) in enumerate(train_loader):\n",
    "        # 这里调用一下train方法, 我们将模型设定为training形态. 等同于nnet.mode(True)\n",
    "        # 除了train模式还有eval模式\n",
    "        # 我们通常要在batch的for循环内部启用train模式, 而不是在外部.\n",
    "        # 因为如果我们在训练过程中调用了test函数,我们就会进eval模式,直到下一次train函数被调用。\n",
    "        # 这就导致了每一个epoch中只有一个batch使用了dropout ,这就导致了我们看到的性能下降。\n",
    "        nnet.train()\n",
    "\n",
    "        # 传入数据\n",
    "        output = nnet(data)\n",
    "\n",
    "        # 将输出数据和目标值输入进去计算一次损失值\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # 建梯度清零\n",
    "        # 反向传播以前都需要将梯度清零, 因为如果不清零pytorch会将上次计算的梯度和本次计算的梯度进行累加\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 对于当前的图片结束以后进行反向传播, 求导计算\n",
    "        loss.backward()\n",
    "\n",
    "        # 将优化其中的权重参数全部更新, 更新权重参数, 准备进行重新计算\n",
    "        # 所有的optimizer都实现了step()方法, 这个方法会更新所有的参数。\n",
    "        optimizer.step()\n",
    "\n",
    "        # 将当前准确率放入全局容器中, 用来展示, 可以删除\n",
    "        train_right = accuracy(output, target)  # 返回的是一个tuple, (准确个数, 总体个数)\n",
    "        train_rights.append(train_right)\n",
    "\n",
    "        if index % 100 == 0:  # 展示准确率\n",
    "            # 设置当前模式为eval模式, 也就是计算模式\n",
    "            nnet.eval()\n",
    "            val_rights = []\n",
    "            # 将测试机的数据进行输出一遍, 查看错误率\n",
    "            for (data, target) in test_loader:\n",
    "                output = nnet(data)\n",
    "                right = accuracy(output, target)  # 得到错误率, 返回总共多少正确的和总体长度\n",
    "                val_rights.append(right)  # 将当前的测试集正确率放到容器中\n",
    "            # 计算出当前训练集的准确率\n",
    "            train_rate = (sum([rate_pair[0] for rate_pair in train_rights]),\n",
    "                          sum([rate_pair[1] for rate_pair in train_rights]))\n",
    "            # 计算出测试集的准确率\n",
    "            val_rate = (sum([rate_pair[0] for rate_pair in val_rights]),\n",
    "                        sum([rate_pair[1] for rate_pair in val_rights]))\n",
    "            print(\"当前epoch: {} [{}/{} ({:.0f}%)] 损失: {:.6f} | 训练集准确率：{:.2f}% 测试集正确率: {:.2f}%\".format(\n",
    "                epoch, index * batch_size, len(train_loader.dataset),\n",
    "                100. * index / len(train_loader),\n",
    "                loss.data,\n",
    "                100. * train_rate[0].numpy() / train_rate[1],\n",
    "                100. * val_rate[0].numpy() / val_rate[1]\n",
    "            ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3337b69b12cc8969cc5aa5ef666d7e6bfd05654ef6c8c61e6103dbb336c66c2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
