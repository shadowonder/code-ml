{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "原理就是在每一层创建一个新的节点用来保留当前这段文字的状态. 然后计算下一个单词的时候使用这个新的节点和x一起计算. 详情略\n",
    "\n",
    "创建一个简单的Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2506, -1.5040,  0.2194,  0.6614, -1.3048]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "word_2_idx = {\"hello\": 0, \"world\": 1}  # 创建一个索引\n",
    "\n",
    "lookup_tensor = torch.tensor([word_2_idx[\"hello\"]], dtype=torch.long)\n",
    "\n",
    "# 使用pytorch初始化一个embedding, 2个单词5个维度的embedding. 注意, 这个初始化使用的就是随机生成的\n",
    "embeds = nn.Embedding(2, 5)\n",
    "hello_embed = embeds(lookup_tensor)  # 查看一个\"hello\"这个词的feature向量.\n",
    "print(hello_embed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接使用Glove查看. 这里使用的glove需要下载一个新的包. \n",
    "\n",
    "```shell\n",
    "pip install pytorch-nlp\n",
    "```\n",
    "\n",
    "如果直接使用的会下载一个2Gb组有的包, 这个包里面已经初始化好了一个100维feature的向量."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2523,  0.1018, -0.6748,  0.2112,  0.4349,  0.1654,  0.4826, -0.8122,\n",
       "         0.0413,  0.7850, -0.0779, -0.6632,  0.1464, -0.2929, -0.2549,  0.0193,\n",
       "        -0.2026,  0.9823,  0.0283, -0.0813, -0.1214,  0.1313, -0.1765,  0.1356,\n",
       "        -0.1636, -0.2257,  0.0550, -0.2031,  0.2072,  0.0958,  0.2248,  0.2154,\n",
       "        -0.3298, -0.1224, -0.4003, -0.0794, -0.1996, -0.0151, -0.0791, -0.1813,\n",
       "         0.2068, -0.3620, -0.3074, -0.2442, -0.2311,  0.0980,  0.1463, -0.0627,\n",
       "         0.4293, -0.0780, -0.1963,  0.6509, -0.2281, -0.3031, -0.1248, -0.1757,\n",
       "        -0.1465,  0.1536, -0.2952,  0.1510, -0.5173, -0.0336, -0.2311, -0.7833,\n",
       "         0.0180, -0.1572,  0.0229,  0.4964,  0.0292,  0.0567,  0.1462, -0.1919,\n",
       "         0.1624,  0.2390,  0.3643,  0.4526,  0.2456,  0.2380,  0.3140,  0.3487,\n",
       "        -0.0358,  0.5611, -0.2535,  0.0520, -0.1062, -0.3096,  1.0585, -0.4202,\n",
       "         0.1822, -0.1126,  0.4058,  0.1178, -0.1971, -0.0753,  0.0807, -0.0278,\n",
       "        -0.1562, -0.4468, -0.1516,  0.1692,  0.0983, -0.0319,  0.0871,  0.2608,\n",
       "         0.0027,  0.1319,  0.3444, -0.3789, -0.4114,  0.0816, -0.1167, -0.4371,\n",
       "         0.0111,  0.0994,  0.2661,  0.4002,  0.1890, -0.1844, -0.3036, -0.2725,\n",
       "         0.2247, -0.4061,  0.1562, -0.1604,  0.4715,  0.0080,  0.5686,  0.2193,\n",
       "        -0.1118,  0.7993,  0.1071, -0.5015,  0.0636,  0.0695,  0.1529, -0.2747,\n",
       "        -0.2099,  0.2074, -0.1068,  0.4065, -2.6438, -0.3114, -0.3216, -0.2646,\n",
       "        -0.3562,  0.0700, -0.1884,  0.4877, -0.2617, -0.0208,  0.1782,  0.1576,\n",
       "        -0.1375,  0.0565,  0.3077, -0.0661,  0.4748, -0.2734,  0.0973, -0.2083,\n",
       "         0.0039,  0.3460, -0.0870, -0.5492, -0.1876, -0.1717,  0.0603, -0.1352,\n",
       "         0.1042,  0.3016,  0.0580,  0.2187, -0.0736, -0.2042, -0.2528, -0.1047,\n",
       "        -0.3216,  0.1252, -0.3128,  0.0097, -0.2678, -0.6112, -0.1109, -0.1365,\n",
       "         0.0351, -0.4939,  0.0849, -0.1549, -0.0635, -0.2394,  0.2827,  0.1085,\n",
       "        -0.3365, -0.6076,  0.3858, -0.0095,  0.1750, -0.5272,  0.6221,  0.1954,\n",
       "        -0.4898,  0.0366, -0.1280, -0.0168,  0.2565, -0.3170,  0.4826, -0.1418,\n",
       "         0.1105, -0.3098, -0.6314, -0.3727,  0.2318, -0.1427, -0.0234,  0.0223,\n",
       "        -0.0447, -0.1640, -0.2585,  0.1629,  0.0248,  0.2335,  0.2793,  0.3900,\n",
       "        -0.0590,  0.1135,  0.1567,  0.1858, -0.1981, -0.4812, -0.0351,  0.0785,\n",
       "        -0.4983,  0.1085, -0.2013,  0.0529, -0.1158, -0.1601,  0.1677,  0.4236,\n",
       "        -0.2311,  0.0825,  0.2430, -0.1679,  0.0080,  0.0859,  0.3803,  0.0730,\n",
       "         0.1633,  0.2470, -0.1109,  0.1512, -0.2207, -0.0619, -0.0371, -0.0879,\n",
       "        -0.2318,  0.1504, -0.1909, -0.1911, -0.1189,  0.0949, -0.0043,  0.1536,\n",
       "        -0.4120, -0.3073,  0.1838,  0.4021, -0.0035, -0.1092, -0.6952,  0.1016,\n",
       "        -0.0793,  0.4033,  0.2228, -0.1937, -0.1331,  0.0732,  0.0998,  0.1169,\n",
       "        -0.2164, -0.1108,  0.1034,  0.0973,  0.1120, -0.3894, -0.0089,  0.2881,\n",
       "        -0.1079,  0.0288,  0.3255,  0.2605, -0.0389,  0.0752,  0.4603, -0.0629,\n",
       "         0.2166,  0.1787, -0.5192,  0.3359])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchnlp.word_to_vector import GloVe\n",
    "\n",
    "vectors = GloVe()\n",
    "vectors[\"hello\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer\n",
    "\n",
    "$$[Batch, features] @ [Hiddens, features]^T + [Batch, Hiddens] @ [Hiddens , Hiddens]^T$$\n",
    "\n",
    "比如我们创建一个神经网络进行训练, 一个batch进来的时候是3个单词, 然后我们对这个神经网络定义的每一个单词的向量数为100, 每一层进行计算使用的hidden临时weight的数量为20. 这里$[3,20]$是上一次计算得到的结果. 那么以此计算得到的公式就是\n",
    "\n",
    "$$[30,100]@[20,100]^T+[3,20]@[20,20]^T=[3,20]$$\n",
    "\n",
    "这里简单看一下rnn的一层的架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0'])\n",
      "torch.Size([10, 10]) torch.Size([10, 100]) torch.Size([10]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 建立一个100维的词向量, 然后使用10个hidden或者称为临时节点.\n",
    "rnn = nn.RNN(100, 10)\n",
    "print(rnn._parameters.keys())\n",
    "\n",
    "print(\n",
    "    rnn.weight_hh_l0.shape,  # hidden,hidden 的矩阵大小\n",
    "    rnn.weight_ih_l0.shape,  # input, hidden 的矩阵大小 10,100 这里需要转置\n",
    "    rnn.bias_hh_l0.shape,\n",
    "    rnn.bias_ih_l0.shape,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化使用到的参数:\n",
    "\n",
    "- input_size 输入维度, 单词的维度\n",
    "- hidden_size memory或者叫hidden的属性\n",
    "- num_layer 默认为1, 如果使用的话就可以使用多层神经网络.\n",
    "\n",
    "forward(x,$h_0$) 给定当前的x, 注意这里是x不是x的转置. $h_0$表示的就是[layer,b,10] \n",
    "\n",
    "输出就是$h_t$,也就是最后一刻输出的结果[layer,b,10], 如果一层的话就是简单的[1,b,10], 也就是简单的$h$\n",
    "\n",
    "整体的输出会输出全部的单词输出量, 也就是从$h_0$到$h_t$的最终权重输出, 比如我们有5个单词, 输出就是[5,b,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(100, 20)\n",
      "torch.Size([10, 3, 20]) torch.Size([1, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 定义一个100维的循环神经网络, memory为20维度, 单层\n",
    "rnn = nn.RNN(input_size=100, hidden_size=20, num_layers=1)\n",
    "print(rnn)\n",
    "\n",
    "# 我们这里模拟一个输入, 10个单词, 3个句子, 每个单词100维向量\n",
    "# 需要注意的是, 我们定义的是一个时间序列输入, 因此最外层需要是词的数量, 想象一下三维空间, 最外层的轴需要是词, 这样才能一个一个词进行训练.\n",
    "x = torch.rand(10, 3, 100)\n",
    "out, h = rnn(x, torch.zeros(1, 3, 20))\n",
    "print(out.shape, h.shape)  # h就是最后一个输出, out就是所有单词,每一次训练的输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0', 'weight_ih_l1', 'weight_hh_l1', 'bias_ih_l1', 'bias_hh_l1'])\n",
      "torch.Size([10, 10]) torch.Size([10, 100])\n",
      "torch.Size([10, 10]) torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(100, 10, num_layers=2)\n",
    "print(rnn._parameters.keys())\n",
    "\n",
    "print(rnn.weight_hh_l0.shape, rnn.weight_ih_l0.shape)\n",
    "print(rnn.weight_hh_l1.shape, rnn.weight_ih_l1.shape)  # 这里的内部状态不需要转换, 输入就是第一层的内部状态.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(100, 10, num_layers=4)\n",
      "torch.Size([10, 3, 10]) torch.Size([4, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(100, 10, num_layers=4)\n",
    "print(rnn)\n",
    "\n",
    "x = torch.randn(10, 3, 100)\n",
    "out, h = rnn(x)\n",
    "print(out.shape, h.shape) # h0是4层\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNCell: 更加灵活的输入. 只会单纯的输入和输出进行. 具有和RNN类相同的输入和输出. \n",
    "\n",
    "- input_size 输入维度, 单词的维度\n",
    "- hidden_size memory或者叫hidden的属性\n",
    "- num_layer 默认为1, 如果使用的话就可以使用多层神经网络.\n",
    "\n",
    "但是在forward参数就不同了, RNNCell使用的是`rnncell(xt,h)`. \n",
    "\n",
    "比如此处我们输入3个句子, 每一个句子的第一个单词, 这个单词有100维的向量, 因此输入的X就是$[3,100]$. 第二个参数就是memory, 比如我们有4层, 然后使用10个隐藏节点进行计算. 那么我们的h就是$[4,3,10]$. 最终的输出就是所有h的状态的集合, 注意我们并不知道有多少个h,所以大小可能是动态的. \n",
    "\n",
    "> 这种方法更像是神经网络的训练模式, 一个一个词进行feed in这样就得到了一个比较合适的输入方法. RNN默认情况下需要指定长度, 因此很可能出现截取或者填充等问题. 尽管这种方法比较底层, 但是却是比较常用的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([10, 3, 100])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(\"x:\", x.shape)\n",
    "cell1 = nn.RNNCell(100, 20)  # 创建一个cell时间序列\n",
    "h1 = torch.zeros(3, 20)  # 创建一个当前memory的容器\n",
    "\n",
    "for xt in x:\n",
    "    h1 = cell1(xt, h1)  # 进行一次计算求导, 我们得到了当前序列节点新的memory\n",
    "\n",
    "print(h1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([10, 3, 100])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(\"x:\", x.shape)\n",
    "\n",
    "# 我们创建一个多序列节点的结构\n",
    "cell1 = nn.RNNCell(100, 30)\n",
    "cell2 = nn.RNNCell(30, 20)  # 这里的输入是第一层的输出\n",
    "h1 = torch.zeros(3, 30)\n",
    "h2 = torch.zeros(3, 20)\n",
    "for xt in x:\n",
    "    h1 = cell1(xt, h1)\n",
    "    h2 = cell2(h1, h2)  # 第二个cell需要输入第一个cell的h\n",
    "\n",
    "print(h2.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 波形案例\n",
    "\n",
    "我们可以使用numpy来定义正弦波形, 这里我们有50个点, 然后用50个点预测后面的状态. 因此, 我们的输入就是[50,b,1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps: [ 1.          1.20408163  1.40816327  1.6122449   1.81632653  2.02040816\n",
      "  2.2244898   2.42857143  2.63265306  2.83673469  3.04081633  3.24489796\n",
      "  3.44897959  3.65306122  3.85714286  4.06122449  4.26530612  4.46938776\n",
      "  4.67346939  4.87755102  5.08163265  5.28571429  5.48979592  5.69387755\n",
      "  5.89795918  6.10204082  6.30612245  6.51020408  6.71428571  6.91836735\n",
      "  7.12244898  7.32653061  7.53061224  7.73469388  7.93877551  8.14285714\n",
      "  8.34693878  8.55102041  8.75510204  8.95918367  9.16326531  9.36734694\n",
      "  9.57142857  9.7755102   9.97959184 10.18367347 10.3877551  10.59183673\n",
      " 10.79591837 11.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_time_steps = 50\n",
    "\n",
    "# 初始相位,我们是随机进行采样. 我们随机的初始化位置, 也就是初始化图像\n",
    "start = np.random.randint(3, size=1)[0]\n",
    "# 进行training数据进行生成\n",
    "time_steps = np.linspace(start, start + 10, num_time_steps)\n",
    "print(\"time_steps:\", time_steps)\n",
    "# 根据这50个点, 生成50个sin的结果\n",
    "data = np.sin(time_steps)\n",
    "data = data.reshape(num_time_steps, 1)\n",
    "# 在这里, 我们输入就是0-48个点, 然后输出需要得到1-49点成为结果, 也就是比原来多1个点\n",
    "x = torch.tensor(data[:-1]).float().view(1, num_time_steps - 1, 1)\n",
    "y = torch.tensor(data[1:]).float().view(1, num_time_steps - 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 16\n",
    "output_size = 1\n",
    "lr = 0.01\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,  # 这里我们定义了batch为第一个维度 [b,seq,h], 这样更好使用\n",
    "        )\n",
    "        self.linear = nn.Linear(hidden_size, output_size)  # 最终添加一个全连接层, output size 就是1\n",
    "\n",
    "    # 这里输出就是[batch, seq, h], h:[b,1,h]\n",
    "    def forward(self, x, hidden_prev):\n",
    "        out, hidden_prev = self.rnn(x, hidden_prev)\n",
    "        # [b, seq, h]\n",
    "        out = out.view(-1, hidden_size)  # 我们这里直接进行flattern操作\n",
    "        out = self.linear(out)  # 线性输出就是[seq,1], 也就输出了一个结果\n",
    "        out = out.unsqueeze(dim=0)  # 这里我们对y进行比较, 所以添加了一个维度, y的维度是[b,seq,1], 因为我们需要用MSE\n",
    "        return out, hidden_prev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 loss 0.4079281687736511\n",
      "Iteration: 1000 loss 0.0012061619199812412\n",
      "Iteration: 2000 loss 0.0009604257065802813\n",
      "Iteration: 3000 loss 0.0005868563894182444\n",
      "Iteration: 4000 loss 9.899263386614621e-05\n",
      "Iteration: 5000 loss 0.0001778372679837048\n"
     ]
    }
   ],
   "source": [
    "# 这里我们需要用mse, 因为结果是线性结果\n",
    "model = Net()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "# 这里我们新建h0, [b, layer, hiddensize]\n",
    "hidden_prev = torch.zeros(1, 1, hidden_size)\n",
    "\n",
    "# 循环6000次\n",
    "for iter in range(6000):\n",
    "    # 随机生成xy\n",
    "    start = np.random.randint(3, size=1)[0]\n",
    "    time_steps = np.linspace(start, start + 10, num_time_steps)\n",
    "    data = np.sin(time_steps)\n",
    "    data = data.reshape(num_time_steps, 1)\n",
    "    x = torch.tensor(data[:-1]).float().view(1, num_time_steps - 1, 1)\n",
    "    y = torch.tensor(data[1:]).float().view(1, num_time_steps - 1, 1)\n",
    "\n",
    "    output, hidden_prev = model(x, hidden_prev)\n",
    "    hidden_prev = hidden_prev.detach()\n",
    "\n",
    "    # 计算mse\n",
    "    loss = criterion(output, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % 1000 == 0:\n",
    "        print(\"Iteration: {} loss {}\".format(iter, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 进行预测\n",
    "\n",
    "# 这里进行预测\n",
    "predictions = []\n",
    "# 取第一个sequence\n",
    "input = x[:, 0, :]\n",
    "for _ in range(x.shape[1]):\n",
    "    # 然后将其拉伸成[b,seq,1]\n",
    "    input = input.view(1, 1, 1)\n",
    "    (pred, hidden_prev) = model(input, hidden_prev)\n",
    "    input = pred\n",
    "    predictions.append(pred.detach().numpy().ravel()[0])\n",
    "\n",
    "x = x.data.numpy().ravel()\n",
    "y = y.data.numpy()\n",
    "plt.scatter(time_steps[:-1], x.ravel(), s=90)\n",
    "plt.plot(time_steps[:-1], x.ravel())\n",
    "\n",
    "plt.scatter(time_steps[1:], predictions)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里我们可以看到, 我们的input大小其实是1, 但是我们训练的时候要求input是49.\n",
    "\n",
    "其实pytorch是可以自行调整input的大小的. 只要满足broadcast的结构, 就可以进行修正"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f5fd407444611a7de458766408d8f0b30a2f26501ee96cb5dac23e78b64d77c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
