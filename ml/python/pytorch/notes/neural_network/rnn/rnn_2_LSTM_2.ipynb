{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: True\n",
      "GPU: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e115b70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchtext.datasets import IMDB\n",
    "\n",
    "print(\"GPU:\", torch.backends.mps.is_available())\n",
    "print(\"GPU:\", torch.cuda.is_available())\n",
    "device = torch.device(\"mps\")\n",
    "torch.manual_seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TEXT = data.Field(tokenize=\"spacy\")\n",
    "# LABEL = data.LabelField(dtype=torch.float)\n",
    "# train_data, test_data = IMDB.splits(TEXT, LABEL)\n",
    "#\n",
    "# print(\"len of train data:\", len(train_data))\n",
    "# print(\"len of test data:\", len(test_data))\n",
    "#\n",
    "# print(train_data.examples[15].text)\n",
    "# print(train_data.examples[15].label)\n",
    "#\n",
    "# # word2vec, glove\n",
    "# TEXT.build_vocab(train_data, max_size=10000, vectors=\"glove.6B.100d\")\n",
    "# LABEL.build_vocab(train_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "需要注意的是, 在新版当中, tokenlizer的TEXT和FIELD已经移除了, 可以使用utils中的get_tokenizer和vacob包来进行分词处理. 而输出的结果label也变成了1和2. 原本的输出应该是pos,neg\n",
    "\n",
    "这里我们简单的创建一个vocab, 后面我们会使用Glove来进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe, vocab\n",
    "\n",
    "train_data_iter, test_data_iter = IMDB(split=(\"train\", \"test\"))\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "\n",
    "# 这里指定一个最大单词数量. 这里使用的build_vocab_from_iterator本质就是一个string to index. 简写为stoi.\n",
    "def get_vocab(train_data_pipe):\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        yield_tokens(train_data_pipe), specials=[\"<UNK>\", \"<PAD>\"], max_tokens=10000\n",
    "    )\n",
    "    vocab.set_default_index(vocab[\"<UNK>\"])\n",
    "    return vocab\n",
    "\n",
    "\n",
    "# 在新版当中我们使用Vocab包对数据进行编码, 获得所有的词汇量\n",
    "# build_vocab_from_iterator：根据给定的迭代器yield_tokens(train_iter)，来构造一个Vocab对象。具体的Vocab类的介绍Vocab类。\n",
    "# 得到一个库,就是将文本转为编码\n",
    "train_vocab = get_vocab(train_data_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "['i', 'have', 'a', 'apple']\n",
      "[13, 33, 6, 7316]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_vocab))\n",
    "sentence = \"i have a apple\"\n",
    "sentence_token = tokenizer(sentence)\n",
    "print(sentence_token)\n",
    "print(train_vocab(sentence_token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 建立rnn网络\n",
    "# 注意, 这里建立的是LSTM网络, 而不是LSTMCell, 所以需要固定长度\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        # 在构造函数中构建embedding. 这里直接将输入的vocabulary数量转换为一个宽度为embedding_dim的矩阵\n",
    "        # 这里我们可以设置一个embedding为10000, 剩下的单词为不知道, 只使用一万个单词. 每一个单词维度是100\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # 构建lstm层, 这里的我们使用了两层lstm, 100个词维度, 256个memory. 也就是c和h都是memory.\n",
    "        # 这里设置了bidirection\n",
    "        self.rnn = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, num_layers=2, bidirectional=True, dropout=0.5\n",
    "        )\n",
    "        # 将h层作为输出层, 输出为1\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [seq,b,1] => [seq,b,100]\n",
    "        # 每一个单词生成一个向量, 一个用b句话\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "\n",
    "        # output: [seq, b, hid_dim*2]\n",
    "        # hidden/h: [num_layers*2, b, hid_dim]\n",
    "        # cell/c: [num_layers*2, b, hid_di]\n",
    "        # 需要注意的是, 由于我们使用的是双向的神经网络, 所以所有的weight都是两倍的\n",
    "        output, (h, c) = self.rnn(embedding)\n",
    "\n",
    "        # 这里我们将h的两个维度拿过来做一个concat, 由于是双向的, 会有两个维度, h1和h2.\n",
    "        # 这里我们使用的是h也就是最后的一个时间序列来进行计算\n",
    "        # [num_layers*2, b, hid_dim] => 2 of [b, hid_dim] => [b, hid_dim*2]\n",
    "        h = torch.cat([h[-2], h[-1]], dim=1)\n",
    "\n",
    "        # 将上面concat以后得向量送入全连接层\n",
    "        h = self.dropout(h)\n",
    "        out = self.fc(h)  # 输出大小为[b]的向量\n",
    "        return out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在新版本中, TEXT和FIELD都不存在了, torchtext中增加了两个类 Vocab和Vectors. 同时GloVe embedding也独立成为一个可下载工具.\n",
    "\n",
    "这里我们直接引用, 引用会下载在cache中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe, vocab\n",
    "\n",
    "# 由于我们的单词只用100维, 这里就用100维, 默认300\n",
    "# 需要注意的是, 只有6b才有100维向量, 默认的向量不存在100维\n",
    "glove_vectors = GloVe(dim=100, name=\"6B\")\n",
    "glove_vocab = vocab(glove_vectors.stoi, 0)\n",
    "glove_vocab.insert_token(\"<unk>\", 0)\n",
    "# this is necessary otherwise it will throw runtime error if OOV token is queried\n",
    "glove_vocab.set_default_index(0)\n",
    "pretrained_embeddings = glove_vectors.vectors\n",
    "pretrained_embeddings = torch.cat(\n",
    "    (torch.zeros(1, pretrained_embeddings.shape[1]), pretrained_embeddings)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        [-0.1077,  0.1105,  0.5981,  ..., -0.8316,  0.4529,  0.0826],\n",
       "        ...,\n",
       "        [ 0.3609, -0.1692, -0.3270,  ...,  0.2714, -0.2919,  0.1611],\n",
       "        [-0.1046, -0.5047, -0.4933,  ...,  0.4253, -0.5125, -0.1705],\n",
       "        [ 0.2837, -0.6263, -0.4435,  ...,  0.4368, -0.8261, -0.1570]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过词, 创建LSTM\n",
    "# 注意: 这里我们直接用了embedding的长度来进行训练, 但是如果可以的话, 可以使用数据源的长度来进行训练.\n",
    "rnn = RNN(len(glove_vocab), 100, 256)\n",
    "# 将embedding的weight放入到我们自定义的embedding里面\n",
    "rnn.embedding.weight.data.copy_(pretrained_embeddings)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用之前, 我们重新定义一下dataloader. 同样,在原先的版本中,dataloader的定义比较简单. 在新版本中我们需要手动定义数据格式."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def text_transform(text):\n",
    "    vocab = glove_vocab(tokenizer(text))\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def label_transform(target):\n",
    "    label = torch.tensor([target - 1], dtype=torch.float32)\n",
    "    return label\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_transform(_label))\n",
    "        processed_text = torch.tensor(text_transform(_text))\n",
    "        text_list.append(processed_text)\n",
    "    return torch.tensor(label_list), pad_sequence(text_list, padding_value=3.0)\n",
    "\n",
    "\n",
    "train_iter = IMDB(split=\"train\")\n",
    "train_dataloader = DataLoader(\n",
    "    list(train_iter), batch_size=8, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_iter = IMDB(split=\"test\")\n",
    "test_dataloader = DataLoader(\n",
    "    list(test_iter), batch_size=8, shuffle=True, collate_fn=collate_batch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(400001, 100)\n",
       "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(rnn.parameters(), lr=1e-3)\n",
    "criteon = nn.BCEWithLogitsLoss().to(device)\n",
    "rnn.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def binary_acc(preds, y):\n",
    "    \"\"\"\n",
    "    get accuracy\n",
    "    \"\"\"\n",
    "    preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = torch.eq(preds, y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "## 训练环节\n",
    "def train(epoch, rnn, iterator, optimizer, criteon):\n",
    "\n",
    "    avg_acc = []\n",
    "    rnn.train()\n",
    "\n",
    "    for i, (l, t) in enumerate(iterator):\n",
    "        label, text = l.to(device), t.to(device)\n",
    "        pred = rnn(text).squeeze(1)\n",
    "\n",
    "        loss = criteon(pred, label)  # 计算一下loss\n",
    "        # 我们计算一下train的准确率\n",
    "        acc = binary_acc(pred, label).item()\n",
    "        avg_acc.append(acc)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\n",
    "                \"Epoch: {} with [{}] step, current accuracy: {}\".format(epoch, i, acc)\n",
    "            )\n",
    "\n",
    "    avg_acc = np.array(avg_acc).mean()\n",
    "    print(\"avg acc:\", avg_acc)\n",
    "\n",
    "\n",
    "## 测试环节\n",
    "def eval(epoch, rnn, iterator, criteon):\n",
    "    avg_acc = []\n",
    "    rnn.eval()\n",
    "    with torch.no_grad():  # 关闭梯度信息\n",
    "        for (l, t) in iterator:\n",
    "            label, text = l.to(device), t.to(device)\n",
    "            # [b, 1] => [b]\n",
    "            pred = rnn(text).squeeze(1)\n",
    "            loss = criteon(pred, label)\n",
    "            acc = binary_acc(pred, label).item()  # 计算一个准确度\n",
    "            avg_acc.append(acc)\n",
    "\n",
    "    avg_acc = np.array(avg_acc).mean()\n",
    "    print(\"with epoch {} we have accuracy in test: {}\".format(epoch, avg_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 with [0] step, current accuracy: 0.5\n",
      "Epoch: 0 with [10] step, current accuracy: 0.625\n",
      "Epoch: 0 with [20] step, current accuracy: 0.5\n",
      "Epoch: 0 with [30] step, current accuracy: 0.25\n",
      "Epoch: 0 with [40] step, current accuracy: 0.5\n",
      "Epoch: 0 with [50] step, current accuracy: 0.0\n",
      "Epoch: 0 with [60] step, current accuracy: 0.0\n",
      "Epoch: 0 with [70] step, current accuracy: 0.0\n",
      "Epoch: 0 with [80] step, current accuracy: 0.0\n",
      "Epoch: 0 with [90] step, current accuracy: 0.0\n",
      "Epoch: 0 with [100] step, current accuracy: 0.0\n",
      "Epoch: 0 with [110] step, current accuracy: 0.0\n",
      "Epoch: 0 with [120] step, current accuracy: 0.0\n",
      "Epoch: 0 with [130] step, current accuracy: 0.0\n",
      "Epoch: 0 with [140] step, current accuracy: 0.0\n",
      "Epoch: 0 with [150] step, current accuracy: 0.0\n",
      "Epoch: 0 with [160] step, current accuracy: 0.0\n",
      "Epoch: 0 with [170] step, current accuracy: 0.0\n",
      "Epoch: 0 with [180] step, current accuracy: 0.0\n",
      "Epoch: 0 with [190] step, current accuracy: 0.0\n",
      "Epoch: 0 with [200] step, current accuracy: 0.0\n",
      "Epoch: 0 with [210] step, current accuracy: 0.0\n",
      "Epoch: 0 with [220] step, current accuracy: 0.0\n",
      "Epoch: 0 with [230] step, current accuracy: 0.0\n",
      "Epoch: 0 with [240] step, current accuracy: 0.0\n",
      "Epoch: 0 with [250] step, current accuracy: 0.0\n",
      "Epoch: 0 with [260] step, current accuracy: 0.0\n",
      "Epoch: 0 with [270] step, current accuracy: 0.0\n",
      "Epoch: 0 with [280] step, current accuracy: 0.0\n",
      "Epoch: 0 with [290] step, current accuracy: 0.0\n",
      "Epoch: 0 with [300] step, current accuracy: 0.0\n",
      "Epoch: 0 with [310] step, current accuracy: 0.0\n",
      "Epoch: 0 with [320] step, current accuracy: 0.0\n",
      "Epoch: 0 with [330] step, current accuracy: 0.0\n",
      "Epoch: 0 with [340] step, current accuracy: 0.0\n",
      "Epoch: 0 with [350] step, current accuracy: 0.0\n",
      "Epoch: 0 with [360] step, current accuracy: 0.0\n",
      "Epoch: 0 with [370] step, current accuracy: 0.0\n",
      "Epoch: 0 with [380] step, current accuracy: 0.0\n",
      "Epoch: 0 with [390] step, current accuracy: 0.0\n",
      "Epoch: 0 with [400] step, current accuracy: 0.0\n",
      "Epoch: 0 with [410] step, current accuracy: 0.0\n",
      "Epoch: 0 with [420] step, current accuracy: 0.0\n",
      "Epoch: 0 with [430] step, current accuracy: 0.0\n",
      "Epoch: 0 with [440] step, current accuracy: 0.0\n",
      "Epoch: 0 with [450] step, current accuracy: 0.0\n",
      "Epoch: 0 with [460] step, current accuracy: 0.0\n",
      "Epoch: 0 with [470] step, current accuracy: 0.0\n",
      "Epoch: 0 with [480] step, current accuracy: 0.0\n",
      "Epoch: 0 with [490] step, current accuracy: 0.0\n",
      "Epoch: 0 with [500] step, current accuracy: 0.0\n",
      "Epoch: 0 with [510] step, current accuracy: 0.0\n",
      "Epoch: 0 with [520] step, current accuracy: 0.0\n",
      "Epoch: 0 with [530] step, current accuracy: 0.0\n",
      "Epoch: 0 with [540] step, current accuracy: 0.0\n",
      "Epoch: 0 with [550] step, current accuracy: 0.0\n",
      "Epoch: 0 with [560] step, current accuracy: 0.0\n",
      "Epoch: 0 with [570] step, current accuracy: 0.0\n",
      "Epoch: 0 with [580] step, current accuracy: 0.0\n",
      "Epoch: 0 with [590] step, current accuracy: 0.0\n",
      "Epoch: 0 with [600] step, current accuracy: 0.0\n",
      "Epoch: 0 with [610] step, current accuracy: 0.0\n",
      "Epoch: 0 with [620] step, current accuracy: 0.0\n",
      "Epoch: 0 with [630] step, current accuracy: 0.0\n",
      "Epoch: 0 with [640] step, current accuracy: 0.0\n",
      "Epoch: 0 with [650] step, current accuracy: 0.0\n",
      "Epoch: 0 with [660] step, current accuracy: 0.0\n",
      "Epoch: 0 with [670] step, current accuracy: 0.0\n",
      "Epoch: 0 with [680] step, current accuracy: 0.0\n",
      "Epoch: 0 with [690] step, current accuracy: 0.0\n",
      "Epoch: 0 with [700] step, current accuracy: 0.0\n",
      "Epoch: 0 with [710] step, current accuracy: 0.0\n",
      "Epoch: 0 with [720] step, current accuracy: 0.0\n",
      "Epoch: 0 with [730] step, current accuracy: 0.0\n",
      "Epoch: 0 with [740] step, current accuracy: 0.0\n",
      "Epoch: 0 with [750] step, current accuracy: 0.0\n",
      "Epoch: 0 with [760] step, current accuracy: 0.0\n",
      "Epoch: 0 with [770] step, current accuracy: 0.0\n",
      "Epoch: 0 with [780] step, current accuracy: 0.0\n",
      "Epoch: 0 with [790] step, current accuracy: 0.0\n",
      "Epoch: 0 with [800] step, current accuracy: 0.0\n",
      "Epoch: 0 with [810] step, current accuracy: 0.0\n",
      "Epoch: 0 with [820] step, current accuracy: 0.0\n",
      "Epoch: 0 with [830] step, current accuracy: 0.0\n",
      "Epoch: 0 with [840] step, current accuracy: 0.0\n",
      "Epoch: 0 with [850] step, current accuracy: 0.0\n",
      "Epoch: 0 with [860] step, current accuracy: 0.0\n",
      "Epoch: 0 with [870] step, current accuracy: 0.0\n",
      "Epoch: 0 with [880] step, current accuracy: 0.0\n",
      "Epoch: 0 with [890] step, current accuracy: 0.0\n",
      "Epoch: 0 with [900] step, current accuracy: 0.0\n",
      "Epoch: 0 with [910] step, current accuracy: 0.0\n",
      "Epoch: 0 with [920] step, current accuracy: 0.0\n",
      "Epoch: 0 with [930] step, current accuracy: 0.0\n",
      "Epoch: 0 with [940] step, current accuracy: 0.0\n",
      "Epoch: 0 with [950] step, current accuracy: 0.0\n",
      "Epoch: 0 with [960] step, current accuracy: 0.0\n",
      "Epoch: 0 with [970] step, current accuracy: 0.0\n",
      "Epoch: 0 with [980] step, current accuracy: 0.0\n",
      "Epoch: 0 with [990] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1000] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1010] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1020] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1030] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1040] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1050] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1060] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1070] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1080] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1090] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1100] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1110] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1120] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1130] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1140] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1150] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1160] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1170] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1180] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1190] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1200] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1210] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1220] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1230] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1240] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1250] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1260] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1270] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1280] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1290] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1300] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1310] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1320] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1330] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1340] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1350] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1360] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1370] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1380] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1390] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1400] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1410] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1420] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1430] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1440] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1450] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1460] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1470] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1480] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1490] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1500] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1510] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1520] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1530] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1540] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1550] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1560] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1570] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1580] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1590] step, current accuracy: 0.0\n",
      "Epoch: 0 with [1600] step, current accuracy: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train(epoch, rnn, train_dataloader, optimizer, criteon)\n\u001b[1;32m      3\u001b[0m     \u001b[39meval\u001b[39m(epoch, rnn, test_dataloader, criteon)\n",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, rnn, iterator, optimizer, criteon)\u001b[0m\n\u001b[1;32m     27\u001b[0m avg_acc\u001b[39m.\u001b[39mappend(acc)\n\u001b[1;32m     29\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 30\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     31\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch, rnn, train_dataloader, optimizer, criteon)\n",
    "    eval(epoch, rnn, test_dataloader, criteon)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "4f5fd407444611a7de458766408d8f0b30a2f26501ee96cb5dac23e78b64d77c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
