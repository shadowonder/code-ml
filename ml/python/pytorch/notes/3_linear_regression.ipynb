{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 一个线性回归的模型\n",
    "构造一组数据x何其对应的标签y\n",
    "\n",
    "## 使用cpu进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values=[i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1,1) # 将array转换为矩阵\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values=[2*i +1 for i in x_values]\n",
    "y_train = np.array(x_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "构建一个线性回归的模型. 线性回归就是一个不加激活函数的全连接层."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# 定义一个类集成nn.Model类\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(LinearRegressionModel,self).__init__()\n",
    "        self.linear=nn.Linear(input_dim,output_dim) # 全连接层, 输入和输出的长度, 下面定义的都是1\n",
    "    def forward(self,x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel(\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "model = LinearRegressionModel(input_dim,output_dim)\n",
    "# 这里的模型就是一个简单的全连接层\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "指定好参数和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 1000 # 迭代1000次\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate) # 回归优化器, parameters就是优化的参数\n",
    "criterion = nn.MSELoss(); # 损失函数的类型, 这里用的是交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 , loss 0.0896872952580452\n",
      "Epoch 100 , loss 0.05115422233939171\n",
      "Epoch 150 , loss 0.02917645126581192\n",
      "Epoch 200 , loss 0.016641169786453247\n",
      "Epoch 250 , loss 0.009491496719419956\n",
      "Epoch 300 , loss 0.005413589999079704\n",
      "Epoch 350 , loss 0.0030877008102834225\n",
      "Epoch 400 , loss 0.0017611081711947918\n",
      "Epoch 450 , loss 0.001004478894174099\n",
      "Epoch 500 , loss 0.0005729169934056699\n",
      "Epoch 550 , loss 0.0003267706779297441\n",
      "Epoch 600 , loss 0.0001863776269601658\n",
      "Epoch 650 , loss 0.00010630281758494675\n",
      "Epoch 700 , loss 6.062987813493237e-05\n",
      "Epoch 750 , loss 3.4582022635731846e-05\n",
      "Epoch 800 , loss 1.972367499547545e-05\n",
      "Epoch 850 , loss 1.1249919225519989e-05\n",
      "Epoch 900 , loss 6.416294581867987e-06\n",
      "Epoch 950 , loss 3.6596031804947415e-06\n",
      "Epoch 1000 , loss 2.0872867025900632e-06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch+=1\n",
    "    # 将行转换成tensor\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    labels = torch.from_numpy(y_train)\n",
    "    \n",
    "    # 每一次迭代的时候梯度清零\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 向前传播一次\n",
    "    outputs = model.forward(inputs)\n",
    "    \n",
    "    # 使用损失函数方程计算损失函数\n",
    "    loss = criterion(outputs,labels)\n",
    "    \n",
    "    # 反向传播, 就是进行一次求导过程\n",
    "    loss.backward()\n",
    "    \n",
    "    # 更新权重参数, 准备进行重新计算\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 输出一次\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch {} , loss {}\".format(epoch,loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "预测模型的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6875865e-03],\n",
       "       [1.0023006e+00],\n",
       "       [2.0019135e+00],\n",
       "       [3.0015266e+00],\n",
       "       [4.0011396e+00],\n",
       "       [5.0007524e+00],\n",
       "       [6.0003653e+00],\n",
       "       [6.9999785e+00],\n",
       "       [7.9995914e+00],\n",
       "       [8.9992046e+00],\n",
       "       [9.9988174e+00]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model(torch.from_numpy(x_train).requires_grad_()).data.numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "保存模型到本地, 保存的是一个字典, 这里指保存参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./models/lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./models/lr_model.pkl'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用gpu进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    class LinearRegessionModel(nn.Module):\n",
    "        def __init__(self,input_dim,output_dim):\n",
    "            super(LinearRegressionModel,self).__init__()\n",
    "            self.Linear=nn.Linear(input_dim,output_dim)\n",
    "            \n",
    "        def forward(self,x):\n",
    "            out=self.linear(x)\n",
    "            return out\n",
    "    input_dim=1\n",
    "    output_dim=1\n",
    "    model=LinearRegressionModel(input_dim,output_dim)\n",
    "    device=torch.device(\"cuda:0\"if torch.cuda.is_available() else \"cpu\") #如果GPU配置好了，那就用GPU；否则用CPU\n",
    "    model.to(device) #将模型放入到GPU中去\n",
    "    crierion=nn.MSELoss()\n",
    "    learning_rate=0.01\n",
    "    optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "    #将数据传入GPU\n",
    "    epochs=1000\n",
    "    for epoch in range(epochs):\n",
    "        epoch+=1\n",
    "        inputs=torch.from_numpy(x_train).to(device) # 同样将所有需要使用的都放入gpu\n",
    "        outputs=torch.from_numpy(y_train).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch %50==0:\n",
    "            print(\"epoch {},loss {}\".format(epoch,loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
