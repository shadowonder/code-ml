{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 基本使用\n",
    "创建一个矩阵. 生成一个tensor一个矩阵计算单元."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "### 0纬标量\n",
    "a = torch.tensor(2,2)\n",
    "a.shape # torch.size([])\n",
    "\n",
    "### 一维标量(张量)\n",
    "torch.tensor([1.1]) # tensor([1.1000])\n",
    "\n",
    "torch.tensor([1.1, 2.2]) # 一维的张亮\n",
    "torch.FloatTensor(1) # 随机出是一个长度为1 的向量\n",
    "torch.FloatTensor(2) # tensor([3.123e-25, 4.5935e-41])\n",
    "\n",
    "data=np.ones(2)\n",
    "torch.from_numpy(data) # 将numpy转换为torch的tensor\n",
    "\n",
    "## 获取长度\n",
    "a = torch.ones(2)\n",
    "a.shape # 获取形状 torch.size([2])\n",
    "\n",
    "a = torch.randn(2,3) # 2行3列的数据\n",
    "a.shape # torch.size([2,3])\n",
    "\n",
    "a.size(0) # 2\n",
    "a.size(1) # 3\n",
    "a.shape[1] # 3\n",
    "\n",
    "## 基本操作\n",
    "\n",
    "a = torch.rand(1,2,3) # 3维的数据tensor([[[...]]])\n",
    "a.shape # torch.Size([1,2,3])\n",
    "\n",
    "\n",
    "## 4维适合图片\n",
    "a = torch.rand(2,3,28,28) # 2个图片, 每个图片3各通道 28*28\n",
    "a[0] # 获取第一张图片\n",
    "\n",
    "## \n",
    "a.numel() # 获取数据大小, 2x3x28x28 内存大小\n",
    "\n",
    "a.dim() # 数据维度\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "创建一个随机矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1107, 0.1877, 0.4203],\n",
       "        [0.0684, 0.3864, 0.9011],\n",
       "        [0.9199, 0.7657, 0.7367],\n",
       "        [0.7840, 0.4721, 0.7770],\n",
       "        [0.5672, 0.8139, 0.6677]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "创建一个全零矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "直接传入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "创建一个全1的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5607, -0.7254,  0.4328],\n",
       "        [-0.0619, -0.1240, -0.8223],\n",
       "        [-0.7475, -0.6366, -1.9925],\n",
       "        [ 0.3631,  0.9454,  0.5187],\n",
       "        [ 0.9116, -0.7669, -0.5843]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5, 3, dtype=torch.double)  # 类型是double\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "显示矩阵大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3665,  0.0613,  0.8953],\n",
       "        [ 0.5126,  0.3929, -0.6094],\n",
       "        [-0.6991, -0.4866, -1.9647],\n",
       "        [ 0.6069,  1.1183,  1.0745],\n",
       "        [ 1.3125, -0.0456,  0.3654]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "x + y  # torch.add(x,y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([28, 28])\n",
      "tensor(0.0501)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 3, 28, 28)\n",
    "print(a[0].shape)\n",
    "print(a[0, 0].shape)\n",
    "print(a[0, 0, 2, 4])  # 返回标量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7254, -0.1240, -0.6366,  0.9454, -0.7669])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 28, 28])\n",
      "torch.Size([2, 1, 28, 28])\n",
      "torch.Size([2, 2, 28, 28])\n",
      "torch.Size([2, 1, 28, 28])\n",
      "torch.Size([4, 3, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "print(a[:2].shape)  # 从开始到第二张图片, 不包含第二张图片.\n",
    "print(a[:2, :1, :, :].shape)  # 从开始到第二张图片的第一个颜色通道, : 表示获取全部\n",
    "print(a[:2, 1:, :, :].shape)  # 从开始到第二张图片的第一个通道后面的颜色通道, : 表示获取全部\n",
    "print(a[:2, -1:, :, :].shape)  # 从开始到第二张图片的最后一个通道 (从倒数第一个到最后一个)\n",
    "print(a[:, :, ::2, ::2].shape)  # 所有图片, 所有通道, 每一个图片横向每隔2个点取一个, 纵向每隔两个点取一个\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 28, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不规则采样\n",
    "a.index_select(0, torch.tensor([0, 2])).shape  # 第一个维度采样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 8, 28])\n"
     ]
    }
   ],
   "source": [
    "print(a.index_select(2, torch.arange(8)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 28, 28])\n",
      "torch.Size([3, 28, 28])\n",
      "torch.Size([4, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 任意多的维度\n",
    "print(a[...].shape)  # 取所有的维度, 类似于javascript的 {...,proj}\n",
    "print(a[0, ...].shape)\n",
    "print(a[:, 1, ...].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False, False],\n",
       "        [False,  True, False,  True],\n",
       "        [False, False,  True, False]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 掩码索引\n",
    "x = torch.randn(3, 4)\n",
    "mask = x.ge(0.5)  # 获取大于等于0.5的矩阵\n",
    "mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5466, 0.5430, 0.6332, 0.6789])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(x, mask)  # 直接获取满足mask的数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take\n",
    "src = torch.tensor([[4, 3, 5], [6, 7, 8]])\n",
    "# 将数据flatern, 然后直接获取list中的数据\n",
    "torch.take(src, torch.tensor([0, 2, 5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "view可以改变矩阵的维度\n",
    "\n",
    "rand和randn的区别在于随机出来的数字\n",
    "- rand 随机出来的数字是均匀分布的\n",
    "- randn 随机出来的数字是正态分布的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # -1表示自动计算维度\n",
    "print(x.size(), y.size(), z.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3758, -2.2452,  0.7844,  0.1207, -0.0840,  0.0589, -0.1131, -0.4516,\n",
       "        -0.0988, -0.0664])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正态分布\n",
    "torch.normal(mean=torch.full([10], 0.0), std=torch.arange(1.0, 0.0, -0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 9, 9],\n",
       "        [9, 9, 9]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full([2, 3], 9)  # 生成矩阵\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full([2], 7)  # 两个7的数列\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 10)  # 1-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  3.3333,  6.6667, 10.0000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 等差数列切分\n",
    "torch.linspace(0, 10, steps=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.7743, 0.5995, 0.4642, 0.3594, 0.2783, 0.2154, 0.1668, 0.1292,\n",
       "        0.1000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10的0次方, 然后log递减\n",
    "torch.logspace(0, -1, steps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对轴矩阵\n",
    "# 超越正方形大小的用0填充\n",
    "torch.eye(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 2, 9, 6, 7, 8, 4, 1, 5])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机打散, 一般用来做索引的种子\n",
    "torch.randperm(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "与numpy协同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones([2, 3])\n",
    "b = torch.from_numpy(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 3.2000])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用list进行导入\n",
    "torch.tensor([2.0, 3.2])  # 小写的接受真是的数据, 大写的接受数据的维度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 3.2000])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([2.0, 3.2])  # 可以使用小写的代替, 很容易混淆\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1.2, 3]).type()  # 默认使用的是floattensor\n",
    "\n",
    "# 设置默认tensortype, 一般增强学习的时候会用, 精度会跟高, 但是计算更耗时\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 常见的tenser格式\n",
    "- scalar\n",
    "- vector\n",
    "- matrix\n",
    "- n-dimensional tensor\n",
    "\n",
    "### Scalar\n",
    "通常就是一个简单的数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "\n",
    "x = tensor(42)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dim()  # 查看维度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(84)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * x  # 运算操作\n",
    "x.mul(2)  # 和上面一样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.item()  # 获取原始数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 6],\n",
       "        [6, 6]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matmul 矩阵相乘, 注意mm()方法只适合二位数组, 因此, 尽量使用matmul()\n",
    "a = torch.tensor([[3, 3], [3, 3]])\n",
    "b = torch.tensor([[1, 1], [1, 1]])\n",
    "a.matmul(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 6],\n",
       "        [6, 6]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b  # matmul() 等同\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 神经网络线性层\n",
    "# 我们有4个照片 拉平以后成为了784个\n",
    "x = torch.rand(4, 784)\n",
    "w = torch.rand(512, 784)  # 一个784*512的矩阵, 注意这里使用的pytorch的写法, 输出在前面, 所以下面的需要转置\n",
    "(x @ w.t()).shape  # 注意转置只适合于二维. 这就是前向传播\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意: 多维矩阵相乘只会对最后一个维度进行矩阵相乘, 这也是我们需要的."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3],\n",
      "        [3, 3]])\n",
      "tensor([[9, 9],\n",
      "        [9, 9]])\n",
      "tensor([[9, 9],\n",
      "        [9, 9]])\n",
      "tensor([[27, 27],\n",
      "        [27, 27]])\n",
      "tensor([[1.7321, 1.7321],\n",
      "        [1.7321, 1.7321]])\n",
      "tensor([[1.7321, 1.7321],\n",
      "        [1.7321, 1.7321]])\n"
     ]
    }
   ],
   "source": [
    "# 平方\n",
    "a = torch.full([2, 2], 3)\n",
    "print(a)\n",
    "print(a.pow(2))\n",
    "print(a**2)\n",
    "print(a**3)\n",
    "print(a**0.5)\n",
    "print(a.sqrt())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7183, 2.7183],\n",
      "        [2.7183, 2.7183]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# exp e的n次方\n",
    "a = torch.exp(torch.ones(2, 2))\n",
    "print(a)\n",
    "print(torch.log(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.) tensor(4.) tensor(3.) tensor(0.1400) tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(3.14)\n",
    "print(a.floor(), a.ceil(), a.trunc(), a.frac(), a.round())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### vector\n",
    "向量, 一般表示这某一个特征,比如 [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5000, -0.5000,  3.0000])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tensor([1.5, -0.5, 3])\n",
    "v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.dim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Matrix\n",
    "一般都是矩阵, 通常都是多维的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = tensor([[1, 2], [3, 4]])  # 直接传入一个list就可以\n",
    "M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  6],\n",
       "        [ 9, 12]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * M  # 简单的标量乘法, 每一个都乘一遍\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 10],\n",
       "        [15, 22]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.matmul(M)  # 矩阵乘法, 和numpy的@还有matmul方法作用相同. 需要满足乘法要求\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([1, 0]).matmul(M)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度挤压和维度扩张 (Squeeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 28, 28])\n",
      "torch.Size([1, 4, 3, 28, 28])\n",
      "torch.Size([4, 3, 28, 28, 1])\n",
      "torch.Size([1, 32, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze新增维度\n",
    "a = torch.rand(4, 3, 28, 28)\n",
    "print(a.shape)\n",
    "# 在第0个维度上添加一个维度\n",
    "print(a.unsqueeze(0).shape)  # 添加了一个新的维度 (就是外面增加了一个中括号[...])\n",
    "print(a.unsqueeze(-1).shape)  # 最后一个数据上增加一个新的维度\n",
    "\n",
    "b = torch.rand(32)\n",
    "b = b.unsqueeze(1).unsqueeze(2).unsqueeze(0)\n",
    "print(b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n",
      "torch.Size([32, 1, 1])\n",
      "torch.Size([1, 32, 1])\n",
      "torch.Size([1, 32, 1, 1])\n",
      "torch.Size([32, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(b.squeeze().shape)\n",
    "print(b.squeeze(0).shape)\n",
    "print(b.squeeze(-1).shape)\n",
    "print(b.squeeze(1).shape)  # 维度不能被挤压, 因为有数据\n",
    "print(b.squeeze(-4).shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度扩展, 比如维度0的数据从1增加到4, 这里的数据进行了复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 1, 1])\n",
      "torch.Size([4, 32, 14, 14])\n",
      "torch.Size([1, 32, 1, 14])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 32, 14, 14)\n",
    "print(b.shape)  # torch.Size([1, 32, 1, 1])\n",
    "print(b.expand(4, 32, 14, 14).shape)\n",
    "print(b.expand(-1, -1, -1, 14).shape)  # -1表示保持不变\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 1, 1])\n",
      "torch.Size([2, 64, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(b.shape)  # torch.Size([1, 32, 1, 1])\n",
    "print(b.repeat(2, 2, 2, 2).shape)  # 每一个维度的数据进行重复, 所有维度的数据数量加倍\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose 维度交换, 将两个维度的大小交换\n",
    "\n",
    "注意, 维度必须好好跟踪, 否则就会出现维度丢失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n",
      "torch.Size([4, 3, 32, 32])\n",
      "torch.Size([4, 3, 32, 32])\n",
      "tensor(False)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 3, 32, 32)\n",
    "print(a.shape)\n",
    "# contiguous 将数据变为连续型数据, 然后就可以进行拉伸操作, 然后在重新合并, 注意这样会丢掉原始数据的顺序\n",
    "a1 = a.transpose(1, 3).contiguous().view(4, 3 * 32 * 32).view(4, 3, 32, 32)\n",
    "a2 = (\n",
    "    a.transpose(1, 3)\n",
    "    .contiguous()\n",
    "    .view(4, 3 * 32 * 32)\n",
    "    .view(4, 32, 32, 3)\n",
    "    .transpose(1, 3)\n",
    ")\n",
    "print(a1.shape)\n",
    "print(a2.shape)\n",
    "# 对比两个矩阵的数据是否相同\n",
    "print(torch.all(torch.eq(a, a1)))\n",
    "print(torch.all(torch.eq(a, a2)))  # 可以看到a2才和a相同, 数据结构没有丢失, 维度必须好好跟踪\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permute\n",
    "\n",
    "Transpose使用是两两交换, permute就是直接定义顺序, 更加强大更加便捷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 28, 28, 3])\n",
      "torch.Size([4, 32, 28, 3])\n",
      "torch.Size([4, 28, 32, 3])\n",
      "torch.Size([4, 28, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 3, 28, 28)\n",
    "print(a.transpose(1, 3).shape)\n",
    "b = torch.rand(4, 3, 28, 32)\n",
    "print(b.transpose(1, 3).shape)\n",
    "print(b.transpose(1, 3).transpose(1, 2).shape)\n",
    "print(b.permute(0, 2, 3, 1).shape)  # 直接对数据进行顺序定义\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcast 扩张, 和expand相似, 且不需要考虑数据\n",
    "\n",
    "插入一个新的维度, 然后扩张成为相同的大小. 可以考虑使用unsqueeze 然后使用expand\n",
    "\n",
    "![4](./assets/4.png)\n",
    "\n",
    "比如, 我们有4个班, 每个班32个学生, 8门课. 我们尝试给每一个人的每一个课都加5分. 数据就是 [4,32,8] 来加一个5. 我们希望直接使用相加来操作, 但是不能, 因为矩阵结构不同, 因此我们需要用unsqueeze来进行维度增加, 然后expand. 而如果我们使用repeat, 我们的5就变成了一个巨大的矩阵, 内存小号扩大了一千倍.\n",
    "\n",
    "此时我们就可以使用braodcast, 但是我们需要注意, **在最小的维度上必须相同**, 比如我们上面的例子, 我们需要扩展的维度必须是8, 因为这是最细粒度的维度.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有一个feature map 4个feature map, 每一个featuremap有32个channel, 然后大小为14*14\n",
    "a = torch.rand(4, 32, 14, 14)\n",
    "# 现在我们需要对32个channel添加偏置参数b, 此时我们的偏执参数为 [1,32,1,1]\n",
    "b = torch.rand(1, 32, 1, 1)  # => [4,32,14,14]\n",
    "c = torch.rand(14, 14)  # => [1,1,14,14] => [4,32,14,14]\n",
    "d = torch.rand(2, 32, 14, 14)  # 维度不同, 不能实现broadcast, 必须手动修改第一个维度\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并和拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 32, 8])\n",
      "torch.Size([4, 3, 2, 16, 32])\n",
      "torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n",
      "torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n"
     ]
    }
   ],
   "source": [
    "# concat\n",
    "a = torch.rand(4, 32, 8)\n",
    "b = torch.rand(5, 32, 8)\n",
    "print(torch.cat([a, b], dim=0).shape)  # 在0维度上合并, 其他维度大小必须相同\n",
    "\n",
    "# stack\n",
    "a = torch.rand(4, 3, 16, 32)\n",
    "b = torch.rand(4, 3, 16, 32)\n",
    "# 新建一个维度, 然后堆叠, stack 堆叠维度必须一样 torch.Size([4, 3, 2, 16, 32])\n",
    "print(torch.stack([a, b], dim=2).shape)\n",
    "\n",
    "# split 根据长度拆分\n",
    "a = torch.rand(32, 8)\n",
    "b = torch.rand(32, 8)\n",
    "c = torch.stack([a, b], dim=0)\n",
    "aa, bb = c.split([1, 1], dim=0)  # 可以使用不均匀拆分[2,1], 按长度来拆分, 总和需要和目标相同\n",
    "print(aa.shape, bb.shape)\n",
    "aa, bb = c.split(1, dim=0)  # 按数量来拆分, 均匀拆分\n",
    "print(aa.shape, bb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1780)\n",
      "tensor(2.4246)\n",
      "tensor([[10.0000, 10.0000, 11.1780],\n",
      "        [10.0000, 10.0000, 10.0000]])\n",
      "tensor([[10.0000, 10.0000, 11.1780],\n",
      "        [10.0000, 10.0000, 10.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Clamp\n",
    "# 梯度裁剪, 一般梯度会很大很大, 可以打印梯度的膜, 一般10-100是比较合适的\n",
    "grad = torch.rand(2, 3)*15\n",
    "print(grad.max())\n",
    "print(grad.median())\n",
    "print(grad.clamp(10))  # 小于10的值直接使用10来代替\n",
    "print(grad.clamp(10, 12))  # 小于10的为10, 大于12的为12\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor的统计属性.\n",
    "\n",
    "norm, mean, sum, prod, max, min argmin, argmax, kthvalue, topk\n",
    "\n",
    "矩阵范数（matrix norm）亦译矩阵模是数学中矩阵论、线性代数、泛函分析等领域中常见的基本概念，是将一定的矩阵空间建立为赋范向量空间时为矩阵装备的范数。应用中常将有限维赋范向量空间之间的映射以矩阵的形式表现，这时映射空间上装备的范数也可以通过矩阵范数的形式表达。\n",
    "\n",
    "![5](./assets/5.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]]])\n",
      "tensor(8.) tensor(8.) tensor(8.)\n",
      "tensor(2.8284) tensor(2.8284) tensor(2.8284)\n",
      "tensor([4., 4.])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# 矩陣範數 norm, 注意不是normalize.\n",
    "\n",
    "a = torch.full([8], 1.)\n",
    "b = a.view(2, 4)\n",
    "c = a.view(2, 2, 2)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "print(a.norm(1), b.norm(1), c.norm(1))\n",
    "print(a.norm(2), b.norm(2), c.norm(2))  # 2范数:元素绝对值得平方和开根号\n",
    "\n",
    "print(b.norm(1, dim=1))  # 对第二个维度求norm, b的维度是[2,4], 就是对4这个维度求norm\n",
    "\n",
    "print(c.norm(1, dim=0))  # 对第一个维度norm, 第一个维度的数据就会消失\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., dtype=torch.float32) tensor(7., dtype=torch.float32) tensor(3.5000, dtype=torch.float32) tensor(0., dtype=torch.float32)\n",
      "tensor(7) tensor(0)\n",
      "tensor(7)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor([5, 8, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(8).view(2, 4).float()\n",
    "print(a.min(), a.max(), a.mean(), a.prod())  # prod 就是都乘起来, 因为有一个0所以结果是0\n",
    "\n",
    "print(a.argmax(), a.argmin())  # 返回最大值最小值所在的索引\n",
    "\n",
    "a = a.view(1, 2, 4)\n",
    "\n",
    "print(a.argmax())\n",
    "print(a.argmin())\n",
    "\n",
    "a = torch.rand(2, 3, 4)\n",
    "print(a.argmax())  # 默认就是拉平为一维的数据, 然后输出\n",
    "\n",
    "a = torch.randn(4, 10)\n",
    "print(a.argmax(dim=1))  # 分别求每列的max index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([2.7879, 2.4704, 1.2700, 1.8708]),\n",
      "indices=tensor([1, 0, 3, 9]))\n",
      "tensor([1, 0, 3, 9])\n",
      "torch.return_types.max(\n",
      "values=tensor([[2.7879],\n",
      "        [2.4704],\n",
      "        [1.2700],\n",
      "        [1.8708]]),\n",
      "indices=tensor([[1],\n",
      "        [0],\n",
      "        [3],\n",
      "        [9]]))\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [3],\n",
      "        [9]])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.randn(4, 10)\n",
    "\n",
    "print(a.max(dim=1))  # 比如神经网络输出一个tensor,可以直接获得最大的概率的位置\n",
    "print(a.argmax(dim=1))\n",
    "\n",
    "# 一般情况下, 对矩阵求出了最大值会消掉一个维度, 添加了keepdim以后 返回结果的维度和之前一样\n",
    "print(a.max(dim=1, keepdim=True))\n",
    "print(a.argmax(dim=1, keepdim=True))\n",
    "print(a.argmax(dim=1).shape)\n",
    "print(a.argmax(dim=1, keepdim=True).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([[1.1128, 0.7538, 0.4773],\n",
      "        [1.1944, 0.6687, 0.6043],\n",
      "        [2.3688, 1.1367, 0.9782],\n",
      "        [0.8497, 0.4598, 0.4395]]),\n",
      "indices=tensor([[8, 9, 3],\n",
      "        [8, 9, 7],\n",
      "        [5, 0, 4],\n",
      "        [3, 0, 6]]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([[-1.0601, -0.9480, -0.8149],\n",
      "        [-1.2304, -0.6507, -0.6449],\n",
      "        [-0.5055, -0.4560, -0.4210],\n",
      "        [-1.7395, -0.8612, -0.5169]]),\n",
      "indices=tensor([[2, 1, 6],\n",
      "        [5, 2, 1],\n",
      "        [6, 8, 3],\n",
      "        [4, 2, 7]]))\n",
      "torch.return_types.kthvalue(\n",
      "values=tensor([0.4773, 0.6043, 0.9782, 0.4395]),\n",
      "indices=tensor([3, 7, 4, 6]))\n"
     ]
    }
   ],
   "source": [
    "# top-k, k-th\n",
    "a = torch.randn(4, 10)\n",
    "print(a.topk(3, dim=1))  # 在第一个维度上获取最大的3个数\n",
    "print(a.topk(3, dim=1, largest=False))  # 在第一个维度上获取最小的3个数\n",
    "\n",
    "\n",
    "print(a.kthvalue(8))  # 排序以后获取从小到大的第8个的值, 注意这是第8小的, 是从小到大\n",
    "print(a.kthvalue(8, dim=1))  # 一共10个数, 第8小就是第三大\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  True, False, False, False, False,  True,  True],\n",
      "        [False, False, False,  True,  True, False,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False,  True,  True, False,  True, False,  True],\n",
      "        [ True, False, False,  True, False, False,  True, False,  True, False]])\n",
      "tensor([[False, False, False,  True, False, False, False, False,  True,  True],\n",
      "        [False, False, False,  True,  True, False,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False,  True,  True, False,  True, False,  True],\n",
      "        [ True, False, False,  True, False, False,  True, False,  True, False]])\n",
      "tensor([[False, False, False,  True, False, False, False, False,  True,  True],\n",
      "        [False, False, False,  True,  True, False,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False,  True,  True, False,  True, False,  True],\n",
      "        [ True, False, False,  True, False, False,  True, False,  True, False]])\n",
      "True\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(a > 0)  # 这里返回大于\n",
    "print(a.gt(0))\n",
    "print(torch.gt(a, 0))\n",
    "\n",
    "print(a.equal(a))  # 返回TrueFalse\n",
    "print(torch.eq(a, a))  # 返回矩阵\n",
    "print(torch.equal(a, a))  # 返回TrueFalse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]]) tensor([[1., 1.],\n",
      "        [1., 1.]]) tensor([[0.6769, 0.7271],\n",
      "        [0.8884, 0.4163]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Where, 三元简单使用\n",
    "# torch.where(condition,x,y) -> tensor\n",
    "cond = torch.tensor([[0.6769, 0.7271], [0.8884, 0.4163]])\n",
    "a = torch.zeros(2, 2)\n",
    "b = torch.ones(2, 2)\n",
    "\n",
    "print(a, b, cond)\n",
    "\n",
    "print(torch.where(cond > 0.5, a, b))  # 大于0.5的时候使用1的位置, 其他情况使用b的位置得值\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gather 查表, 比如有一个list, 然后从torch中的index进行查表操作\n",
    "比如enum是[dog,cat,whale], tensor是[0,1,0,2], 那么结果就应该是[dog,cat,dog,whale]\n",
    "\n",
    "`torch.gather(input,dim,index,out=None) -> Tensor`\n",
    "\n",
    "神经网络输出可以使用查表来进行比对, 可以快速查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 7, 0],\n",
      "        [4, 0, 8],\n",
      "        [8, 2, 3],\n",
      "        [5, 2, 1]])\n",
      "tensor([[10095, 10093, 10086],\n",
      "        [10090, 10086, 10094],\n",
      "        [10094, 10088, 10089],\n",
      "        [10091, 10088, 10087]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prob = torch.randn(4, 10)\n",
    "idx = prob.topk(dim=1, k=3)\n",
    "idx = idx[1]\n",
    "print(idx)  # 得到4个维度中前3大的数字的index\n",
    "label = torch.arange(10) + 10086  # enum的表格, 也就是一个list\n",
    "print(torch.gather(label.expand(4, 10), dim=1, index=idx.long()))  # 根据enum输出\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor 的简单理解:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![image](./assets/2.png)\n",
    "\n",
    "### hub模块\n",
    "调用别人已经训练好的模型.\n",
    "\n",
    "<https://pytorch.org/hub/research-models>\n",
    "\n",
    "<https://github.com/pytorch/hub>\n",
    "\n",
    "下面就调用一下模型. 下载一个文件来进行边框检测. \n",
    "\n",
    "![image](./assets/deeplab1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/shuowang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /Users/shuowang/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n",
      "100%|██████████| 161M/161M [00:05<00:00, 28.4MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): DeepLabHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\"pytorch/vision:v0.10.0\",\n",
    "                       \"deeplabv3_resnet50\", pretrained=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "import urllib\n",
    "\n",
    "url, filename = (\n",
    "    \"https://github.com/pytorch/hub/raw/master/images/deeplab1.png\",\n",
    "    \"assets/deeplab1.png\",\n",
    ")\n",
    "try:\n",
    "    urllib.URLopener().retrieve(url, filename)\n",
    "except:\n",
    "    urllib.request.urlretrieve(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "input_image = input_image.convert(\"RGB\")\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                             0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "input_tensor = preprocess(input_image)\n",
    "# create a mini-batch as expected by the model\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to(\"cuda\")\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)[\"out\"][0]\n",
    "output_predictions = output.argmax(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a color pallette, selecting a color for each class\n",
    "import matplotlib.pyplot as plt\n",
    "palette = torch.tensor([2**25 - 1, 2**15 - 1, 2**21 - 1])\n",
    "colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "\n",
    "# plot the semantic segmentation predictions of 21 classes in each color\n",
    "r = Image.fromarray(output_predictions.byte().cpu().numpy()\n",
    "                    ).resize(input_image.size)\n",
    "r.putpalette(colors)\n",
    "\n",
    "\n",
    "plt.imshow(r)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
